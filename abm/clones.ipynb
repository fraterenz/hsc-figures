{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288dd1a4-1686-4474-9bb8-8f650a59084a",
   "metadata": {},
   "source": [
    "# Quantifying the number of missing clones from simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d86893-4e76-44fa-b023-80c27c624d55",
   "metadata": {},
   "source": [
    "## Context and motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee913b3-f4ad-477c-b0a3-7d2e4b3cd89e",
   "metadata": {},
   "source": [
    "In Mitchell et al. we have many more clones compared to Fabre et al. but also to target seq in general. There are at least 3 explanations for this:\n",
    "1. biased target seq\n",
    "2. different resolutions\n",
    "3. biased WGS single-colony assay\n",
    "\n",
    "### Biased target seq\n",
    "The other idea is that there is a bias in the data. Samples are collected from blood and thus it is likely that not all stem cells are present in the data, as not all stem cells contribute to blood equally at a certain timepoint.\n",
    "\n",
    "### Different resolutions\n",
    "VAF of Mitchell et al. is 0.5% (clone size of 1%), whereas target seq is at 2%.\n",
    "\n",
    "### Biased WGS single-colony assay\n",
    "Is this because cologenic assays (aka WGS single-colony) can be biased by chance when we reduce the 10^5 stem cell pool to a subsample of approx. 300 cells? \n",
    "\n",
    "To test this:\n",
    "1. from the whole stem cell pool get all clone frequencies\n",
    "2. subsample to the accurate number of cells per donor\n",
    "3. count clones with freq >= 2% ?\n",
    "4. compare this to Mitchell et al. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9cd8e-af6f-4cb9-9c1e-26351f6947a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from futils import timeserie\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import socket\n",
    "from pathlib import Path\n",
    "from typing import List, NewType\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "import matplotlib as mpl\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "if socket.gethostname() == \"LAPTOP-CEKCHJ4C\":\n",
    "    font_dirs = [Path(\"~\").expanduser() / \".local/share/fonts/otf/TexGyreHeros/\"]\n",
    "else:\n",
    "    font_dirs = [Path(\"~\").expanduser() / \".local/fonts/TeX-Gyre-Heros/\"]\n",
    "font_files = font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "for font_file in font_files:\n",
    "    font_manager.fontManager.addfont(font_file)\n",
    "mpl.rcParams[\"font.family\"] = [\"TeX Gyre Heros\", \"sans-serif\"]\n",
    "# use sims from ABC instead of the ones specificly for this nb\n",
    "ABC_SIMS = True\n",
    "PATH2SIMS = Path(\"/data/scratch/hfx923/hsc-draft/v4.3.13/100000cells/variant_fraction\")\n",
    "N_SIMS = 10_000\n",
    "SAMPL_SIZ = sorted([300, 10_000])\n",
    "TOT_VAR = 3_000\n",
    "assert len(SAMPL_SIZ) <= 2\n",
    "# assumption is 3_000 possible variants which means\n",
    "# that the size of each vector in csv file is 3_000\n",
    "VAR_IDX = np.arange(0, TOT_VAR, dtype=np.uint64)\n",
    "# clone sizes at which we subsample\n",
    "PCT = [0.005, 0.01, 0.02, 0.04]\n",
    "FIGSIZ = (5.5, 3)\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "re_idx = re.compile(r\"(?P<idx>\\d+)idx.csv\")\n",
    "re_age = re.compile(r\"(?P<age>\\d+)dot(\\d+)years\")\n",
    "CloneId = NewType(\"CloneId\", int)\n",
    "CloneFreq = NewType(\"CloneFreq\", float)\n",
    "CloneCounts = NewType(\"CloneCounts\", int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3c87a-fb6e-4b25-b084-307adb9ec842",
   "metadata": {},
   "source": [
    "## Analyse the simulations to quantify missing clones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f3098-2448-4ddd-ae61-865697497549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_from_clones_freq(\n",
    "    size: int, clones_freq: np.typing.NDArray[CloneFreq], rng: np.random.Generator\n",
    ") -> np.typing.NDArray[CloneId]:\n",
    "    return rng.choice(VAR_IDX, size=size, p=clones_freq)\n",
    "\n",
    "\n",
    "def variant_counts(my_sample: List[CloneId]) -> np.typing.NDArray[CloneCounts]:\n",
    "    return np.unique_counts(my_sample).counts\n",
    "\n",
    "\n",
    "def variants_above_threshold(\n",
    "    variant_counts: np.typing.NDArray[CloneCounts], threshold: CloneCounts\n",
    ") -> int:\n",
    "    return (variant_counts >= threshold).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907bb57d-8fb2-4e0c-b0fe-6d5a6c778906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read variant csv file: vector of size N_VARIANTS (3_000) with\n",
    "#    proportion of cells in each entry representing the variant freq\n",
    "# 2. tot nb of clones is nb of entries in 1. with value > 0, i.e. at\n",
    "#    least one cell for that variant\n",
    "# 3. subsample to two different sample sizes: SAMPL_SIZ. To subsample,\n",
    "#    pick at random `size` clone idx from VAR_IDX with prob given by\n",
    "#    their frequencies in the original data\n",
    "# 4. from this subsample, drop neutral clone which has id 0\n",
    "# 5. compute variants counts (groupby and count) from variants idx\n",
    "# 6. store the number of variants that are present in at least `thresh`\n",
    "#    cells, that is keep variants with a count of at leat `thresh`\n",
    "clones_sims = list()\n",
    "for walking in PATH2SIMS.walk():\n",
    "    bp, my_dir_names = walking[0], walking[1]\n",
    "    for my_dir_name in my_dir_names:\n",
    "        my_dir = bp / my_dir_name\n",
    "        age = int(re_age.search(my_dir.name).group(\"age\"))\n",
    "        assert age >= 0, f\"wrong age {age}\"\n",
    "        for i, file in enumerate(tqdm(my_dir.glob(\"*.csv\"), mininterval=2)):\n",
    "            idx = int(re_idx.search(file.name).group(\"idx\"))\n",
    "            # 1. vector of size N_VARIANTS variant freqs in each entry\n",
    "            variants_f = np.array(timeserie.load_timeserie(file))\n",
    "            # 2. boolean mask\n",
    "            tot_clones = (variants_f > 0).sum()\n",
    "            for sample_size in SAMPL_SIZ:\n",
    "                # 3. subsample `sample_size` variant idx from VAR_IDX to two different\n",
    "                # sample sizes with freq given by `variants_f`\n",
    "                subsample = create_sample_from_clones_freq(sample_size, variants_f, rng)\n",
    "                # 4. drop neutral clone which has id 0\n",
    "                # 5. compute variant counts from variant idx\n",
    "                counts = variant_counts(subsample[subsample > 0])\n",
    "                for j, thresh in enumerate([int(round(sample_size * p)) for p in PCT]):\n",
    "                    # 6. store the variants that are present in at least `thresh` cells\n",
    "                    clones_sims.append(\n",
    "                        (\n",
    "                            age,\n",
    "                            idx,\n",
    "                            variants_above_threshold(counts, thresh),\n",
    "                            sample_size,\n",
    "                            PCT[j] * 100,\n",
    "                            tot_clones,\n",
    "                        )\n",
    "                    )\n",
    "            if i >= N_SIMS:\n",
    "                break\n",
    "\n",
    "print(f\"Loaded {len(clones_sims)} entries\")\n",
    "columns = [\"Age\", \"Id\", \"Sampled clones\", \"Sample\", \"Clone size\", \"Clones\"]\n",
    "df = pd.DataFrame(\n",
    "    clones_sims,\n",
    "    columns=columns,\n",
    "    # dtype=[(col, col_float.get(col, \"uint64\")) for col in columns]\n",
    ")\n",
    "for col in columns:\n",
    "    if col == \"Clone size\":\n",
    "        df[col] = df[col].astype(float)\n",
    "    else:\n",
    "        df[col] = df[col].astype(np.uint64)\n",
    "df[\"Diff\"] = (df[\"Clones\"] - df[\"Sampled clones\"]).astype(np.int64)\n",
    "df = df.pivot(\n",
    "    index=[\"Age\", \"Id\"],\n",
    "    columns=[\"Sample\", \"Clone size\"],\n",
    "    values=[\"Sampled clones\", \"Diff\"],\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4172fbf-2a36-4df3-90e1-30450dcd403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for age in df.index.get_level_values(0).unique():\n",
    "    view_age = df[df.index.get_level_values(\"Age\") == age]\n",
    "    x = sorted(df.columns.get_level_values(\"Sample\").unique())\n",
    "    fig, axes = plt.subplots(\n",
    "        1, 2, figsize=FIGSIZ, sharey=True, sharex=True, layout=\"tight\"\n",
    "    )\n",
    "    for ax, xx in zip(axes, x):\n",
    "        if not age:\n",
    "            sns.histplot(\n",
    "                view_age.loc[:, view_age.columns.get_level_values(\"Sample\") == xx][\n",
    "                    \"Diff\"\n",
    "                ],\n",
    "                discrete=True,\n",
    "                stat=\"density\",\n",
    "                ax=ax,\n",
    "                legend=False,\n",
    "            )\n",
    "        else:\n",
    "            sns.histplot(\n",
    "                view_age.loc[:, view_age.columns.get_level_values(\"Sample\") == xx][\n",
    "                    \"Diff\"\n",
    "                ],\n",
    "                stat=\"density\",\n",
    "                ax=ax,\n",
    "                legend=False,\n",
    "            )\n",
    "            ax.set_xlim([0, 600])\n",
    "        ax.set_xlabel(rf\"$C_{{tot}} - C_{{{xx}}}$\")\n",
    "    fig.suptitle(f\"Number of missing clones for age {age} years\", y=0.95)\n",
    "    fig.savefig(f\"clones_missing_{SAMPL_SIZ[0]}_{SAMPL_SIZ[1]}_{age}years.svg\")\n",
    "    plt.show()\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=FIGSIZ, layout=\"tight\")\n",
    "    assert len(x) == 2\n",
    "    c_diff = (\n",
    "        (\n",
    "            view_age.loc[:, view_age.columns.get_level_values(\"Sample\") == x[-1]][\n",
    "                \"Diff\"\n",
    "            ].droplevel(axis=1, level=0)\n",
    "            - view_age.loc[:, view_age.columns.get_level_values(\"Sample\") == x[0]][\n",
    "                \"Diff\"\n",
    "            ].droplevel(axis=1, level=0)\n",
    "        )\n",
    "        .astype(int)\n",
    "        .melt()\n",
    "    )\n",
    "    sns.histplot(\n",
    "        c_diff, x=\"value\", hue=\"Clone size\", ax=axes[0], element=\"poly\", discrete=True\n",
    "    )\n",
    "    axes[0].set_xlabel(rf\"$C_{{{x[-1]}}} - C_{{{x[0]}}}$\")\n",
    "    sns.boxenplot(\n",
    "        c_diff,\n",
    "        y=\"value\",\n",
    "        x=\"Clone size\",\n",
    "        ax=axes[1],\n",
    "    )\n",
    "    axes[1].plot(\n",
    "        axes[1].get_xticks(),\n",
    "        c_diff.groupby(\"Clone size\").mean(),\n",
    "        c=\"#88419d\",\n",
    "        marker=\"x\",\n",
    "        ls=\"\",\n",
    "        mew=2,\n",
    "        ms=8,\n",
    "    )\n",
    "    axes[1].set_xticks(ticks=axes[1].get_xticks(), labels=[ele * 100 for ele in PCT])\n",
    "    axes[1].set_xlabel(\"Clone size [%]\")\n",
    "    axes[1].set_ylabel(rf\"$C_{{{x[-1]}}} - C_{{{x[0]}}}$\")\n",
    "    fig.suptitle(f\"Difference in subsampled clones for age {age} years\", y=0.95)\n",
    "    axes[0].set_xlim([-20, 20])\n",
    "    axes[1].set_ylim([-20, 20])\n",
    "    fig.savefig(f\"clones_difference_{SAMPL_SIZ[0]}_{SAMPL_SIZ[1]}_{age}years.svg\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsc-figures",
   "language": "python",
   "name": "hsc-figures"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
